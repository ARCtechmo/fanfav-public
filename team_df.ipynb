{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1120c884-58e9-4c69-bdc7-7d5139d977f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This produces the dataframe for NFL Teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fd344e-6edc-4d54-a85f-1b117245fd26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cce6dcf0-04fe-472a-9a00-e8a7152819e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Required installations\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e119c32d-3dff-4e61-a9bb-23cb1d0c6b36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c869bb49-671e-449d-8f50-7497b090cffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## REQUIRED ACTIONS - Include in a README doc ## \n",
    "# modify the season start date in the 'get_current_week' function\n",
    "# modify the number of weeks if the NFL adds regular season games to the schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75fdcba-8369-4c5c-bcbd-6786ac3c6c1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb99a078-98d0-4610-97dd-3e59e854ff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimization update \n",
    "# task: change file location to pull the xlsx files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6394b188-d6a1-4718-8579-dd9325c1fe07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "451c6d33-7366-4724-a6ef-f639b8f597cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "from IPython.display import display\n",
    "import shutil\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36166f1-9988-4fb3-b812-7ba768281837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2710d66f-5327-48b8-b651-0f2b396bd84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Pandas options to display all columns in a single row without wrapping\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de5d8ba-cbb8-4e0d-8bcd-3a441c569d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69ee9cc1-242b-4d1a-89fb-0087a0fe2fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the current week of the NFL season\n",
    "def get_current_week():\n",
    "    current_date = datetime.now()\n",
    "    season_start_date = datetime(2024, 9, 4)  # Update for the season start\n",
    "    current_week = ((current_date - season_start_date).days // 7) + 1\n",
    "    return current_week\n",
    "\n",
    "# Define the current NFL year, week, and season type\n",
    "current_year = datetime.now().year\n",
    "current_week = get_current_week()\n",
    "seasontype = 2 if current_week <= 18 else 3  # Regular season or playoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c510def-7655-4294-8f68-792f936a143b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fce77a26-0d86-42d0-9b75-9b11c809d3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the years to pull\n",
    "# nfl.import_weekly_data(years, columns, downcast)\n",
    "def get_year_range(current_year, current_week, start_year=2017):\n",
    "    if current_week <= 18:  # Regular season\n",
    "        return list(range(start_year, current_year + 1))\n",
    "    else:  # Playoffs\n",
    "        return list(range(start_year, current_year))\n",
    "\n",
    "# Use the function\n",
    "years = get_year_range(current_year, current_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31721960-1f58-45fc-a41f-464e0335987d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b120c571-ed7d-482b-91f6-56bc8dcb461d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a helper function to clean the team stats xlsx files\n",
    "# no output\n",
    "\n",
    "def clean_team_boxscore(filepath):\n",
    "    # Step 1: Read skipping the first header row\n",
    "    df = pd.read_excel(filepath, skiprows=1)\n",
    "\n",
    "    # Step 2: Clean columns\n",
    "    def normalize_col(col):\n",
    "        return (\n",
    "            str(col).replace('\\n', ' ')\n",
    "                    .replace('(', '')\n",
    "                    .replace(')', '')\n",
    "                    .replace('\"', '')\n",
    "                    .replace('#', '')\n",
    "                    .replace('$', '')\n",
    "                    .replace('/', '')\n",
    "                    .replace('-', ' ')\n",
    "                    .strip()\n",
    "                    .lower()\n",
    "                    .replace('  ', ' ')\n",
    "        )\n",
    "    \n",
    "    cleaned_cols = [normalize_col(col) for col in df.columns]\n",
    "    df.columns = cleaned_cols\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98885427-0d8a-4d75-9949-b0d4cf0f2774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ac61e4e-3369-42ec-a79b-cbcbb496d6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Processing team file: 2017-NFL_Box_Score_Team-Stats.xlsx\n",
      "‚úÖ Saved: team_stats_2017_df.csv | Shape: (534, 64)\n",
      "üìÇ Processing team file: 2018-NFL_Box_Score_Team-Stats.xlsx\n",
      "‚úÖ Saved: team_stats_2018_df.csv | Shape: (534, 65)\n",
      "üìÇ Processing team file: 2019-NFL_Box_Score_Team-Stats.xlsx\n",
      "‚úÖ Saved: team_stats_2019_df.csv | Shape: (534, 64)\n",
      "üìÇ Processing team file: 2020-NFL_Box_Score_Team-Stats.xlsx\n",
      "‚úÖ Saved: team_stats_2020_df.csv | Shape: (538, 64)\n",
      "üìÇ Processing team file: 2021-NFL_Box_Score_Team-Stats.xlsx\n",
      "‚úÖ Saved: team_stats_2021_df.csv | Shape: (570, 64)\n",
      "üìÇ Processing team file: 2022-NFL_Box_Score_Team-Stats.xlsx\n",
      "‚úÖ Saved: team_stats_2022_df.csv | Shape: (568, 65)\n",
      "üìÇ Processing team file: 2023-NFL_Box_Score_Team-Stats.xlsx\n",
      "‚úÖ Saved: team_stats_2023_df.csv | Shape: (570, 65)\n",
      "üìÇ Processing team file: 2024-NFL_Box_Score_Team-Stats.xlsx\n",
      "‚úÖ Saved: team_stats_2024_df.csv | Shape: (570, 65)\n"
     ]
    }
   ],
   "source": [
    "# normalize the team names\n",
    "# create dataframes for the team stats for each year\n",
    "# output: team dataframes per year with optional csv files\n",
    "\n",
    "# Team name to abbreviation map (same as before)\n",
    "team_abbr_map = {\n",
    "    'Arizona Cardinals': 'ARI', 'Atlanta Falcons': 'ATL', 'Baltimore Ravens': 'BAL',\n",
    "    'Buffalo Bills': 'BUF', 'Carolina Panthers': 'CAR', 'Chicago Bears': 'CHI',\n",
    "    'Cincinnati Bengals': 'CIN', 'Cleveland Browns': 'CLE', 'Dallas Cowboys': 'DAL',\n",
    "    'Denver Broncos': 'DEN', 'Detroit Lions': 'DET', 'Green Bay Packers': 'GB',\n",
    "    'Houston Texans': 'HOU', 'Indianapolis Colts': 'IND', 'Jacksonville Jaguars': 'JAX',\n",
    "    'Kansas City Chiefs': 'KC', 'Las Vegas Raiders': 'LV', 'Los Angeles Chargers': 'LAC',\n",
    "    'Los Angeles Rams': 'LAR', 'Miami Dolphins': 'MIA', 'Minnesota Vikings': 'MIN',\n",
    "    'New England Patriots': 'NE', 'New Orleans Saints': 'NO', 'New York Giants': 'NYG',\n",
    "    'New York Jets': 'NYJ', 'Philadelphia Eagles': 'PHI', 'Pittsburgh Steelers': 'PIT',\n",
    "    'San Francisco 49ers': 'SF', 'Seattle Seahawks': 'SEA', 'Tampa Bay Buccaneers': 'TB',\n",
    "    'Tennessee Titans': 'TEN', 'Washington Commanders': 'WAS',\n",
    "    \n",
    "    # Legacy names\n",
    "    'Oakland Raiders': 'LV', 'Washington Redskins': 'WAS', 'Washington Football Team': 'WAS'\n",
    "}\n",
    "\n",
    "# Storage\n",
    "team_yearly_dfs = {}\n",
    "team_yearly_files = []\n",
    "\n",
    "for year in years:\n",
    "    team_file = f\"{year}-NFL_Box_Score_Team-Stats.xlsx\"\n",
    "    try:\n",
    "        print(f\"üìÇ Processing team file: {team_file}\")\n",
    "        df = clean_team_boxscore(team_file)\n",
    "\n",
    "        # Add 'season' column from year\n",
    "        df['season'] = year\n",
    "\n",
    "        # Map team abbreviation\n",
    "        df['team_abbr'] = df['team'].map(team_abbr_map)\n",
    "\n",
    "        # Save to dictionary\n",
    "        team_yearly_dfs[year] = df\n",
    "\n",
    "        # ** csv file **\n",
    "        file_name = f\"team_stats_{year}_df.csv\"\n",
    "        # df.to_csv(file_name, index=False)\n",
    "        \n",
    "        team_yearly_files.append(file_name)\n",
    "        print(f\"‚úÖ Saved: {file_name} | Shape: {df.shape}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing {year}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54be633-570d-49fb-a01c-7de5e4e37515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09f0aeed-639d-469b-a3b5-4cbadda260bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÖ Validating 2017...\n",
      "‚úÖ All team_abbr values present.\n",
      "‚úÖ No duplicate season/week/game id/team_abbr rows.\n",
      "‚úÖ All game ids have exactly 2 teams.\n",
      "‚ÑπÔ∏è Nulls in core fields: 0\n",
      "\n",
      "üìÖ Validating 2018...\n",
      "‚úÖ All team_abbr values present.\n",
      "‚úÖ No duplicate season/week/game id/team_abbr rows.\n",
      "‚úÖ All game ids have exactly 2 teams.\n",
      "‚ÑπÔ∏è Nulls in core fields: 0\n",
      "\n",
      "üìÖ Validating 2019...\n",
      "‚úÖ All team_abbr values present.\n",
      "‚úÖ No duplicate season/week/game id/team_abbr rows.\n",
      "‚úÖ All game ids have exactly 2 teams.\n",
      "‚ÑπÔ∏è Nulls in core fields: 0\n",
      "\n",
      "üìÖ Validating 2020...\n",
      "‚úÖ All team_abbr values present.\n",
      "‚úÖ No duplicate season/week/game id/team_abbr rows.\n",
      "‚úÖ All game ids have exactly 2 teams.\n",
      "‚ÑπÔ∏è Nulls in core fields: 0\n",
      "\n",
      "üìÖ Validating 2021...\n",
      "‚úÖ All team_abbr values present.\n",
      "‚úÖ No duplicate season/week/game id/team_abbr rows.\n",
      "‚úÖ All game ids have exactly 2 teams.\n",
      "‚ÑπÔ∏è Nulls in core fields: 0\n",
      "\n",
      "üìÖ Validating 2022...\n",
      "‚úÖ All team_abbr values present.\n",
      "‚úÖ No duplicate season/week/game id/team_abbr rows.\n",
      "‚úÖ All game ids have exactly 2 teams.\n",
      "‚ÑπÔ∏è Nulls in core fields: 0\n",
      "\n",
      "üìÖ Validating 2023...\n",
      "‚úÖ All team_abbr values present.\n",
      "‚úÖ No duplicate season/week/game id/team_abbr rows.\n",
      "‚úÖ All game ids have exactly 2 teams.\n",
      "‚ÑπÔ∏è Nulls in core fields: 0\n",
      "\n",
      "üìÖ Validating 2024...\n",
      "‚úÖ All team_abbr values present.\n",
      "‚úÖ No duplicate season/week/game id/team_abbr rows.\n",
      "‚úÖ All game ids have exactly 2 teams.\n",
      "‚ÑπÔ∏è Nulls in core fields: 0\n"
     ]
    }
   ],
   "source": [
    "for year, df in team_yearly_dfs.items():\n",
    "    print(f\"\\nüìÖ Validating {year}...\")\n",
    "\n",
    "    # 1. Missing team_abbr\n",
    "    missing_abbr = df['team_abbr'].isna().sum()\n",
    "    if missing_abbr == 0:\n",
    "        print(\"‚úÖ All team_abbr values present.\")\n",
    "    else:\n",
    "        print(f\"‚ùå Missing team_abbr: {missing_abbr}\")\n",
    "\n",
    "    # 2. Duplicates per season+week+game_id+team_abbr\n",
    "    dup_keys = ['season', 'week', 'game id', 'team_abbr']\n",
    "    duplicates = df.duplicated(subset=dup_keys).sum()\n",
    "    if duplicates == 0:\n",
    "        print(\"‚úÖ No duplicate season/week/game id/team_abbr rows.\")\n",
    "    else:\n",
    "        print(f\"‚ùå Duplicate rows found: {duplicates}\")\n",
    "\n",
    "    # 3. Unique game_id should have exactly 2 teams\n",
    "    game_counts = df['game id'].value_counts()\n",
    "    bad_games = game_counts[game_counts != 2]\n",
    "    if len(bad_games) == 0:\n",
    "        print(\"‚úÖ All game ids have exactly 2 teams.\")\n",
    "    else:\n",
    "        print(f\"‚ùå {len(bad_games)} game_ids do not have 2 teams.\")\n",
    "\n",
    "    # 4. Optional: Nulls in core fields\n",
    "    core_nulls = df[['season', 'week', 'team', 'team_abbr']].isna().sum().sum()\n",
    "    print(f\"‚ÑπÔ∏è Nulls in core fields: {core_nulls}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d1cb2d-515f-4873-a9e9-d4bd23000ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23f07c1f-c099-4e5a-95cb-08fd46a7270e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Combined shape: (4418, 68)\n",
      "üíæ Saved: team_stats_2017_2024_df.csv\n"
     ]
    }
   ],
   "source": [
    "team_stats_combined_df = pd.concat(team_yearly_dfs.values(), ignore_index=True)\n",
    "\n",
    "# Optional: Save\n",
    "start_year, end_year = min(years), max(years)\n",
    "\n",
    "# ** csv file **\n",
    "combined_filename = f\"team_stats_{start_year}_{end_year}_df.csv\"\n",
    "# team_stats_combined_df.to_csv(combined_filename, index=False)\n",
    "\n",
    "print(f\"‚úÖ Combined shape: {team_stats_combined_df.shape}\")\n",
    "print(f\"üíæ Saved: {combined_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac42cc9-dc50-4d26-981c-f12a6a6cb2d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b0de46d-bcaa-48ac-bc87-d41e6f1def59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a helper function to clean the the dfs salary data\n",
    "# no output\n",
    "\n",
    "def clean_column_dfs(col):\n",
    "    \"\"\"\n",
    "    Cleans and flattens multi-index column names for DFS salary Excel files:\n",
    "    - Joins tuples if multi-index\n",
    "    - Removes special characters\n",
    "    - Normalizes spaces\n",
    "    - Converts to lowercase for matching\n",
    "    \"\"\"\n",
    "    if isinstance(col, tuple):\n",
    "        col = ' '.join(str(x) for x in col if x)\n",
    "\n",
    "    return (\n",
    "        str(col)\n",
    "        .replace('\\n', ' ')\n",
    "        .replace('(', '')\n",
    "        .replace(')', '')\n",
    "        .replace('\"', '')\n",
    "        .replace('#', '')\n",
    "        .replace('$', '')\n",
    "        .replace('/', '')\n",
    "        .replace('-', ' ')\n",
    "        .strip()\n",
    "        .lower()\n",
    "        .replace('  ', ' ')\n",
    "        .replace('   ', ' ')\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327cea16-fe80-4e81-be95-29dbcca4020e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9316021c-3734-49e2-82e9-3a005dcfcd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a helper function to extract the salary and fp data from the the dfs files\n",
    "# no output\n",
    "\n",
    "def process_dfs_salary_file(filepath, year):\n",
    "    # Load raw DFS file\n",
    "    raw = pd.read_excel(filepath, header=[0, 1])\n",
    "    raw.columns = [clean_column_dfs(col) for col in raw.columns]\n",
    "\n",
    "    # Filter to defenses: DK uses 'dst'; FD uses 'dst' or 'd'\n",
    "    raw_filtered = raw[\n",
    "        raw['position draftkings'].str.lower().isin(['dst']) |\n",
    "        raw['position fanduel'].str.lower().isin(['dst', 'd'])\n",
    "    ].copy()\n",
    "\n",
    "    # Fuzzy mapping logic\n",
    "    col_map = {}\n",
    "    for col in raw_filtered.columns:\n",
    "        col_lower = col.lower()\n",
    "        if 'game id' in col_lower:\n",
    "            col_map['game_id'] = col\n",
    "        elif 'player id' in col_lower:\n",
    "            col_map['player_id'] = col\n",
    "        elif 'week' in col_lower:\n",
    "            col_map['week'] = col\n",
    "        elif 'team' in col_lower and 'information' in col_lower:\n",
    "            col_map['team'] = col\n",
    "        elif 'salary' in col_lower and 'draftkings' in col_lower:\n",
    "            col_map['dk_salary'] = col\n",
    "        elif 'salary' in col_lower and 'fanduel' in col_lower:\n",
    "            col_map['fd_salary'] = col\n",
    "        elif 'fantasy points' in col_lower and 'draftkings' in col_lower:\n",
    "            col_map['dk_points'] = col\n",
    "        elif 'fantasy points' in col_lower and 'fanduel' in col_lower:\n",
    "            col_map['fd_points'] = col\n",
    "\n",
    "    # Required columns\n",
    "    required = ['game_id', 'player_id', 'week', 'team', 'dk_salary', 'fd_salary', 'dk_points', 'fd_points']\n",
    "    missing = [k for k in required if k not in col_map]\n",
    "    if missing:\n",
    "        raise KeyError(f\"Missing expected columns: {missing}\")\n",
    "\n",
    "    # Subset and rename\n",
    "    df = raw_filtered[[col_map[k] for k in required]].copy()\n",
    "    df.columns = required\n",
    "\n",
    "    # Add season column\n",
    "    df['season'] = int(year)\n",
    "\n",
    "    # Ensure numeric types\n",
    "    df['week'] = pd.to_numeric(df['week'], errors='coerce')\n",
    "    for col in ['dk_salary', 'fd_salary', 'dk_points', 'fd_points']:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    # Use player_id as team_abbr (works for D/ST)\n",
    "    df['team_abbr'] = df['player_id']\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46106c4d-239d-4d7e-b9a5-ce3b9d0d884f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8bf480a-4583-4fd3-93c7-a1e48144e1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíµ Processing DFS salary file for 2017\n",
      "‚úÖ Saved: team_dfs_2017_df.csv | Shape: (532, 10)\n",
      "\n",
      "üíµ Processing DFS salary file for 2018\n",
      "‚úÖ Saved: team_dfs_2018_df.csv | Shape: (532, 10)\n",
      "\n",
      "üíµ Processing DFS salary file for 2019\n",
      "‚úÖ Saved: team_dfs_2019_df.csv | Shape: (532, 10)\n",
      "\n",
      "üíµ Processing DFS salary file for 2020\n",
      "‚úÖ Saved: team_dfs_2020_df.csv | Shape: (532, 10)\n",
      "\n",
      "üíµ Processing DFS salary file for 2021\n",
      "‚úÖ Saved: team_dfs_2021_df.csv | Shape: (564, 10)\n",
      "\n",
      "üíµ Processing DFS salary file for 2022\n",
      "‚úÖ Saved: team_dfs_2022_df.csv | Shape: (566, 10)\n",
      "\n",
      "üíµ Processing DFS salary file for 2023\n",
      "‚úÖ Saved: team_dfs_2023_df.csv | Shape: (568, 10)\n",
      "\n",
      "üíµ Processing DFS salary file for 2024\n",
      "‚úÖ Saved: team_dfs_2024_df.csv | Shape: (567, 10)\n"
     ]
    }
   ],
   "source": [
    "# create csv files of dfs (salary / fantasy point) for each year\n",
    "# output: csv files for dfs dataframes fo each year\n",
    "dfs_salary_dfs = {}\n",
    "\n",
    "for year in years:\n",
    "    dfs_file = f\"NFL-{year}-DFS-Dataset.xlsx\"\n",
    "    try:\n",
    "        print(f\"\\nüíµ Processing DFS salary file for {year}\")\n",
    "        \n",
    "        # Process and store\n",
    "        df_dfs = process_dfs_salary_file(dfs_file, year)\n",
    "        dfs_salary_dfs[year] = df_dfs\n",
    "\n",
    "        # ** csv file **\n",
    "        output_file = f\"team_dfs_{year}_df.csv\"\n",
    "        # df_dfs.to_csv(output_file, index=False)\n",
    "        print(f\"‚úÖ Saved: {output_file} | Shape: {df_dfs.shape}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing {year}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c58f502-c7c2-4279-8d6c-ae74f509eb06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "817f810a-1436-4f2c-ae37-f7306a16d523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÖ Validating DFS data for 2017...\n",
      "‚úÖ All team_abbr values present.\n",
      "‚úÖ No duplicate season/week/game_id/team_abbr rows.\n",
      "‚ÑπÔ∏è Null salary cells: 6\n",
      "\n",
      "üìÖ Validating DFS data for 2018...\n",
      "‚úÖ All team_abbr values present.\n",
      "‚úÖ No duplicate season/week/game_id/team_abbr rows.\n",
      "‚ÑπÔ∏è Null salary cells: 2\n",
      "\n",
      "üìÖ Validating DFS data for 2019...\n",
      "‚úÖ All team_abbr values present.\n",
      "‚úÖ No duplicate season/week/game_id/team_abbr rows.\n",
      "‚ÑπÔ∏è Null salary cells: 0\n",
      "\n",
      "üìÖ Validating DFS data for 2020...\n",
      "‚úÖ All team_abbr values present.\n",
      "‚úÖ No duplicate season/week/game_id/team_abbr rows.\n",
      "‚ÑπÔ∏è Null salary cells: 0\n",
      "\n",
      "üìÖ Validating DFS data for 2021...\n",
      "‚úÖ All team_abbr values present.\n",
      "‚úÖ No duplicate season/week/game_id/team_abbr rows.\n",
      "‚ÑπÔ∏è Null salary cells: 113\n",
      "\n",
      "üìÖ Validating DFS data for 2022...\n",
      "‚úÖ All team_abbr values present.\n",
      "‚úÖ No duplicate season/week/game_id/team_abbr rows.\n",
      "‚ÑπÔ∏è Null salary cells: 2\n",
      "\n",
      "üìÖ Validating DFS data for 2023...\n",
      "‚úÖ All team_abbr values present.\n",
      "‚úÖ No duplicate season/week/game_id/team_abbr rows.\n",
      "‚ÑπÔ∏è Null salary cells: 0\n",
      "\n",
      "üìÖ Validating DFS data for 2024...\n",
      "‚úÖ All team_abbr values present.\n",
      "‚úÖ No duplicate season/week/game_id/team_abbr rows.\n",
      "‚ÑπÔ∏è Null salary cells: 0\n",
      "\n",
      "‚úÖ Final combined DFS salary shape: (4393, 10)\n",
      "üíæ Saved: team_dfs_2017_2024_df.csv\n"
     ]
    }
   ],
   "source": [
    "# Validation checks \n",
    "# merged all years into a single team dataframe with dfs salary / fantasy points\n",
    "# output: new merged team dfs dataframe with validation checks for each yearly df\n",
    "\n",
    "# Step 1: Validate\n",
    "for year, df in dfs_salary_dfs.items():\n",
    "    print(f\"\\nüìÖ Validating DFS data for {year}...\")\n",
    "\n",
    "    # Check core fields\n",
    "    core_fields = ['season', 'week', 'game_id', 'team_abbr']\n",
    "    missing_cols = [col for col in core_fields if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"‚ùå Missing columns: {missing_cols}\")\n",
    "        continue\n",
    "\n",
    "    # Team_abbr\n",
    "    missing_abbr = df['team_abbr'].isna().sum()\n",
    "    if missing_abbr == 0:\n",
    "        print(\"‚úÖ All team_abbr values present.\")\n",
    "    else:\n",
    "        print(f\"‚ùå Missing team_abbr entries: {missing_abbr}\")\n",
    "\n",
    "    # Duplicate check\n",
    "    dup_rows = df.duplicated(subset=core_fields).sum()\n",
    "    if dup_rows == 0:\n",
    "        print(\"‚úÖ No duplicate season/week/game_id/team_abbr rows.\")\n",
    "    else:\n",
    "        print(f\"‚ùå Duplicate key rows: {dup_rows}\")\n",
    "\n",
    "    # Nulls in salary\n",
    "    nulls = df[['dk_salary', 'fd_salary']].isna().sum().sum()\n",
    "    print(f\"‚ÑπÔ∏è Null salary cells: {nulls}\")\n",
    "\n",
    "# Step 2: Merge\n",
    "team_dfs_combined_df = pd.concat(dfs_salary_dfs.values(), ignore_index=True)\n",
    "\n",
    "# ** csv file ** \n",
    "dfs_combined_filename = f\"team_dfs_{min(years)}_{max(years)}_df.csv\"\n",
    "# team_dfs_combined_df.to_csv(dfs_combined_filename, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Final combined DFS salary shape: {team_dfs_combined_df.shape}\")\n",
    "print(f\"üíæ Saved: {dfs_combined_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fdf410-b341-4a37-b366-1aa14338e778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "816efdbb-2502-4b9f-a487-30c249760ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Using in-memory team_stats_combined_df\n",
      "‚úÖ Using in-memory team_dfs_combined_df\n",
      "\n",
      "‚úÖ Merged shape: (4418, 74)\n",
      "‚ÑπÔ∏è Total salary nulls: 719\n",
      "üíæ Saved: team_stats_dfs_2017_2024_df.csv\n"
     ]
    }
   ],
   "source": [
    "# Data Normalization\n",
    "# updated team stats dataframe and optional csv file\n",
    "\n",
    "# üß† Use in-memory dataframes if available\n",
    "if 'team_stats_combined_df' not in locals():\n",
    "    team_stats_combined_df = pd.read_excel(f\"team_stats_{min(years)}_{max(years)}_df.xlsx\")\n",
    "    print(\"üìÇ Loaded team stats from Excel.\")\n",
    "else:\n",
    "    print(\"‚úÖ Using in-memory team_stats_combined_df\")\n",
    "\n",
    "if 'team_dfs_combined_df' not in locals():\n",
    "    team_dfs_combined_df = pd.read_excel(f\"team_dfs_{min(years)}_{max(years)}_df.xlsx\")\n",
    "    print(\"üìÇ Loaded DFS salary from Excel.\")\n",
    "else:\n",
    "    print(\"‚úÖ Using in-memory team_dfs_combined_df\")\n",
    "\n",
    "# üõ† Normalize key column if needed\n",
    "if 'game id' in team_stats_combined_df.columns:\n",
    "    team_stats_combined_df.rename(columns={'game id': 'game_id'}, inplace=True)\n",
    "\n",
    "# üîç Drop stale salary/point columns if they exist\n",
    "for col in ['dk_salary', 'fd_salary', 'dk_points', 'fd_points']:\n",
    "    if col in team_stats_combined_df.columns:\n",
    "        team_stats_combined_df.drop(columns=col, inplace=True)\n",
    "\n",
    "# üîó Merge on 4 keys\n",
    "team_stats_dfs_merged_df = team_stats_combined_df.merge(\n",
    "    team_dfs_combined_df,\n",
    "    how='left',\n",
    "    on=['season', 'week', 'game_id', 'team_abbr']\n",
    ")\n",
    "\n",
    "# ‚úÖ Final validation\n",
    "print(f\"\\n‚úÖ Merged shape: {team_stats_dfs_merged_df.shape}\")\n",
    "salary_nulls = team_stats_dfs_merged_df[['dk_salary', 'fd_salary']].isna().sum().sum()\n",
    "print(f\"‚ÑπÔ∏è Total salary nulls: {salary_nulls}\")\n",
    "\n",
    "# ** csv file **\n",
    "final_merged_filename = f\"team_stats_dfs_{min(years)}_{max(years)}_df.csv\"\n",
    "# team_stats_dfs_merged_df.to_csv(final_merged_filename, index=False)\n",
    "print(f\"üíæ Saved: {final_merged_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa8553c-4fa7-403e-97c0-071685b5f4c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "429f4472-067b-4b9b-8010-f43604a1a278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering - create defensive columns\n",
    "# no output\n",
    "opp_rename_map = {\n",
    "    '1_opp': 'opp_pts_q1',\n",
    "    '2_opp': 'opp_pts_q2',\n",
    "    '3_opp': 'opp_pts_q3',\n",
    "    '4_opp': 'opp_pts_q4',\n",
    "    'rush_opp': 'opp_rush_att',\n",
    "    'yds_opp': 'opp_rush_yds',\n",
    "    'td_opp': 'opp_rush_tds',\n",
    "    'comp_opp': 'opp_pass_comp',\n",
    "    'att_opp': 'opp_pass_att',\n",
    "    'yds.1_opp': 'opp_pass_yds',\n",
    "    'td.1_opp': 'opp_pass_tds',\n",
    "    'total yards_opp': 'opp_total_yards',\n",
    "    'total plays_opp': 'opp_total_plays',\n",
    "    'time of possession_opp': 'opp_time_of_possession',\n",
    "    'third downs made_opp': 'opp_third_downs_made',\n",
    "    'third downs attempted_opp': 'opp_third_downs_attempts',\n",
    "    'fourth downs made_opp': 'opp_fourth_downs_made',\n",
    "    'fourth downs attempted_opp': 'opp_fourth_downs_attempts',\n",
    "    'sacks_opp': 'opp_sacks',\n",
    "    'interceptions made_opp': 'opp_interceptions'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74637ffd-2db8-490d-8f63-ecb67b7555fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afe86f73-6201-4481-817a-74c8c1de9c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Final shape with opponent features: (4418, 94)\n",
      "üíæ Saved as: team_stats_dfs_merged_features_df.csv\n"
     ]
    }
   ],
   "source": [
    "# merge team stats and dfs dataframes\n",
    "# output: a merged dataframe of team stats and salary / fp data\n",
    "\n",
    "# Self-merge on game context\n",
    "df_merged = team_stats_dfs_merged_df.merge(\n",
    "    team_stats_dfs_merged_df,\n",
    "    how='inner',\n",
    "    on=['season', 'week', 'game_id'],\n",
    "    suffixes=('', '_opp')\n",
    ")\n",
    "\n",
    "# Filter out self-matches\n",
    "df_merged = df_merged[df_merged['team_abbr'] != df_merged['team_abbr_opp']]\n",
    "\n",
    "\n",
    "# Extract and rename\n",
    "df_opp_features = df_merged[list(opp_rename_map.keys())].rename(columns=opp_rename_map)\n",
    "\n",
    "# Combine with original\n",
    "team_stats_dfs_merged_features_df = pd.concat(\n",
    "    [team_stats_dfs_merged_df.reset_index(drop=True), df_opp_features.reset_index(drop=True)],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# *** csv file ***\n",
    "# team_stats_dfs_merged_features_df.to_csv(\"team_stats_dfs_merged_features_df.csv\", index=False)\n",
    "print(f\"‚úÖ Final shape with opponent features: {team_stats_dfs_merged_features_df.shape}\")\n",
    "print(\"üíæ Saved as: team_stats_dfs_merged_features_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff16943-c3c7-4978-bb4a-765c691f2f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce7c3c0c-bc41-40ee-8639-2e6d45cb00f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cleaned & finalized dataframe shape: (4418, 87)\n"
     ]
    }
   ],
   "source": [
    "# Modify columns\n",
    "# output: updated team dataframe (not final)\n",
    "\n",
    "# Rename quarters early\n",
    "quarter_rename_map = {'1': 'q1', '2': 'q2', '3': 'q3', '4': 'q4', 'OT': 'q_ot'}\n",
    "team_stats_dfs_merged_features_df.rename(columns=quarter_rename_map, inplace=True)\n",
    "\n",
    "# Lowercase column map\n",
    "col_map = {col.lower().strip(): col for col in team_stats_dfs_merged_features_df.columns}\n",
    "\n",
    "# Step 2‚Äì3: Resolve target columns\n",
    "base_keys = ['season', 'week', 'date', 'game_id', 'team', 'team_abbr', 'venue',\n",
    "             'dk_salary', 'fd_salary', 'dk_points', 'fd_points']\n",
    "defense_keys = ['sacks', 'opponent fumbles recovered', 'defensive fumble recovery td',\n",
    "                'interception return td', 'blocked punt/fg return td', 'safeties',\n",
    "                'blocked kick/punt', 'interceptions made', 'points_allowed']\n",
    "odds_keys = ['opening_odds', 'opening_spread', 'opening_total',\n",
    "             'line_move1', 'line_move2', 'line_move3',\n",
    "             'closing_odds', 'closing_spread', 'closing_total',\n",
    "             'opening_ml', 'closing_ml']\n",
    "quarter_keys = ['q1', 'q2', 'q3', 'q4', 'q_ot']\n",
    "\n",
    "def resolve_keys(keys): return [col_map[k] for k in keys if k in col_map]\n",
    "\n",
    "base_cols = resolve_keys(base_keys)\n",
    "quarter_cols = resolve_keys(quarter_keys)\n",
    "defensive_cols = resolve_keys(defense_keys)\n",
    "odds_cols = resolve_keys(odds_keys)\n",
    "opp_cols = [col for col in team_stats_dfs_merged_features_df.columns if col.startswith('opp_')]\n",
    "\n",
    "# Reorder\n",
    "final_order = base_cols + quarter_cols + defensive_cols + opp_cols + odds_cols\n",
    "remaining_cols = [col for col in team_stats_dfs_merged_features_df.columns if col not in final_order]\n",
    "\n",
    "team_stats_dfs_merged_features_df = team_stats_dfs_merged_features_df[final_order + remaining_cols]\n",
    "\n",
    "# Drop known noise columns\n",
    "drop_cols = ['unnamed: 62', 'opening moneyline', 'closing moneyline', 'start time (et)',\n",
    "             'start time et', 'player_id', 'team_y', 'bigdataball dataset']\n",
    "team_stats_dfs_merged_features_df.drop(columns=drop_cols, inplace=True, errors='ignore')\n",
    "\n",
    "\n",
    "start_year = years[0]\n",
    "end_year = years[-1]\n",
    "\n",
    "# # ** csv file **\n",
    "# final_filename = f\"team_stats_dfs_{start_year}_{end_year}_df.csv\"\n",
    "# team_stats_dfs_merged_features_df.to_csv(final_filename, index=False)\n",
    "\n",
    "print(f\"‚úÖ Cleaned & finalized dataframe shape: {team_stats_dfs_merged_features_df.shape}\")\n",
    "# print(f\"üíæ Saved as: {final_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d6e9f0-c7ff-42d6-ac7e-beb5a0664d93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12948277-e79c-4c81-b4fa-4b524674c0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Columns not assigned to any group (18):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['blocked kickpunt',\n",
       " 'blocked puntfg return td',\n",
       " 'closing odds',\n",
       " 'closing spread',\n",
       " 'closing total',\n",
       " 'defensive 2pt conversion return',\n",
       " 'halftime',\n",
       " 'line movements 1',\n",
       " 'line movements 2',\n",
       " 'line movements 3',\n",
       " 'moneyline',\n",
       " 'opening odds',\n",
       " 'opening spread',\n",
       " 'opening total',\n",
       " 'points allowed by defense',\n",
       " 'puntkickofffg return td',\n",
       " 'team_x',\n",
       " 'yards.1']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Reordered and renamed dataframe:\n",
      "üìê Shape: (4418, 87)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>week</th>\n",
       "      <th>date</th>\n",
       "      <th>game_id</th>\n",
       "      <th>team_abbr</th>\n",
       "      <th>venue</th>\n",
       "      <th>dk_salary</th>\n",
       "      <th>fd_salary</th>\n",
       "      <th>dk_points</th>\n",
       "      <th>fd_points</th>\n",
       "      <th>q1</th>\n",
       "      <th>q2</th>\n",
       "      <th>q3</th>\n",
       "      <th>q4</th>\n",
       "      <th>ot</th>\n",
       "      <th>final</th>\n",
       "      <th>rush</th>\n",
       "      <th>yds</th>\n",
       "      <th>td</th>\n",
       "      <th>comp</th>\n",
       "      <th>att</th>\n",
       "      <th>yds.1</th>\n",
       "      <th>td.1</th>\n",
       "      <th>yards</th>\n",
       "      <th>net pass yards</th>\n",
       "      <th>total yards</th>\n",
       "      <th>first downs</th>\n",
       "      <th>third downs made</th>\n",
       "      <th>third downs attempted</th>\n",
       "      <th>fourth downs made</th>\n",
       "      <th>fourth downs attempted</th>\n",
       "      <th>total plays</th>\n",
       "      <th>time of possession</th>\n",
       "      <th>extra point return</th>\n",
       "      <th>2p conversions made</th>\n",
       "      <th>extra points made</th>\n",
       "      <th>field goals made</th>\n",
       "      <th>int</th>\n",
       "      <th>sacked</th>\n",
       "      <th>fumbles</th>\n",
       "      <th>lost</th>\n",
       "      <th>turnovers</th>\n",
       "      <th>penalties</th>\n",
       "      <th>sacks</th>\n",
       "      <th>opponent fumbles recovered</th>\n",
       "      <th>defensive fumble recovery td</th>\n",
       "      <th>interception return td</th>\n",
       "      <th>safeties</th>\n",
       "      <th>interceptions made</th>\n",
       "      <th>opp_pts_q1</th>\n",
       "      <th>opp_pts_q2</th>\n",
       "      <th>opp_pts_q3</th>\n",
       "      <th>opp_pts_q4</th>\n",
       "      <th>opp_rush_att</th>\n",
       "      <th>opp_rush_yds</th>\n",
       "      <th>opp_rush_tds</th>\n",
       "      <th>opp_pass_comp</th>\n",
       "      <th>opp_pass_att</th>\n",
       "      <th>opp_pass_yds</th>\n",
       "      <th>opp_pass_tds</th>\n",
       "      <th>opp_total_yards</th>\n",
       "      <th>opp_total_plays</th>\n",
       "      <th>opp_time_of_possession</th>\n",
       "      <th>opp_third_downs_made</th>\n",
       "      <th>opp_third_downs_attempts</th>\n",
       "      <th>opp_fourth_downs_made</th>\n",
       "      <th>opp_fourth_downs_attempts</th>\n",
       "      <th>opp_sacks</th>\n",
       "      <th>opp_interceptions</th>\n",
       "      <th>team_x</th>\n",
       "      <th>yards.1</th>\n",
       "      <th>blocked puntfg return td</th>\n",
       "      <th>puntkickofffg return td</th>\n",
       "      <th>defensive 2pt conversion return</th>\n",
       "      <th>blocked kickpunt</th>\n",
       "      <th>points allowed by defense</th>\n",
       "      <th>opening odds</th>\n",
       "      <th>opening spread</th>\n",
       "      <th>opening total</th>\n",
       "      <th>line movements 1</th>\n",
       "      <th>line movements 2</th>\n",
       "      <th>line movements 3</th>\n",
       "      <th>closing odds</th>\n",
       "      <th>closing spread</th>\n",
       "      <th>closing total</th>\n",
       "      <th>moneyline</th>\n",
       "      <th>halftime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-09-07</td>\n",
       "      <td>42985-KAN@NWE</td>\n",
       "      <td>KC</td>\n",
       "      <td>Road</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>27</td>\n",
       "      <td>185</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>35</td>\n",
       "      <td>368</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>352</td>\n",
       "      <td>537</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>30.233333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>124</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>36</td>\n",
       "      <td>267</td>\n",
       "      <td>0</td>\n",
       "      <td>371</td>\n",
       "      <td>74</td>\n",
       "      <td>29.766667</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Kansas City Chiefs</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>48</td>\n",
       "      <td>7.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>47.5o15</td>\n",
       "      <td>48u15</td>\n",
       "      <td>48u17</td>\n",
       "      <td>47.5o15</td>\n",
       "      <td>8.0</td>\n",
       "      <td>47.5</td>\n",
       "      <td>371.0</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  week       date        game_id team_abbr venue  dk_salary  fd_salary  dk_points  fd_points  q1  q2  q3  q4  ot  final  rush  yds  td  comp  att  yds.1  td.1  yards  net pass yards  total yards  first downs  third downs made  third downs attempted  fourth downs made  fourth downs attempted  total plays  time of possession  extra point return  2p conversions made  extra points made  field goals made  int  sacked  fumbles  lost  turnovers  penalties  sacks  opponent fumbles recovered  defensive fumble recovery td  interception return td  safeties  interceptions made  opp_pts_q1  opp_pts_q2  opp_pts_q3  opp_pts_q4  opp_rush_att  opp_rush_yds  opp_rush_tds  opp_pass_comp  opp_pass_att  opp_pass_yds  opp_pass_tds  opp_total_yards  opp_total_plays  opp_time_of_possession  opp_third_downs_made  opp_third_downs_attempts  opp_fourth_downs_made  opp_fourth_downs_attempts  opp_sacks  opp_interceptions              team_x  yards.1  blocked puntfg return td  puntkickofffg return td  \\\n",
       "0    2017     1 2017-09-07  42985-KAN@NWE        KC  Road        NaN        NaN        NaN        NaN   7   7   7  21 NaN     42    27  185   2    28   35    368     4     16             352          537           26                 4                     11                  0                       0           65           30.233333                   0                    0                  6                 0    0       3        2     1          1         15      3                           0                             0                       0         0                   0           7          10          10           0            35           124             3             16            36           267             0              371               74               29.766667                     5                        15                      0                          2          3                  0  Kansas City Chiefs      139                         0                        0   \n",
       "\n",
       "   defensive 2pt conversion return  blocked kickpunt  points allowed by defense opening odds  opening spread  opening total line movements 1 line movements 2 line movements 3 closing odds  closing spread  closing total  moneyline halftime  \n",
       "0                                0                 0                         27           48             7.0           48.0          47.5o15           48u15             48u17      47.5o15             8.0           47.5      371.0     25.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# *** Final Team Dataframe ***\n",
    "# output: final team dataframe and csv file \n",
    "# Modify the columns and create the final team dataframe dataframe\n",
    "\n",
    "\n",
    "# Column map (lowercase ‚Üí actual)\n",
    "col_map = {col.lower().strip(): col for col in team_stats_dfs_merged_features_df.columns}\n",
    "\n",
    "# Canonical groupings with updates\n",
    "base_keys = ['season', 'week', 'date', 'game_id', 'team_abbr', 'venue']\n",
    "fantasy_keys = ['dk_salary', 'fd_salary', 'dk_points', 'fd_points']\n",
    "offense_keys = [\n",
    "    'q1', 'q2', 'q3', 'q4', 'ot', 'final',\n",
    "    'rush', 'yds', 'td', 'comp', 'att', 'yds.1', 'td.1',\n",
    "    'yards', 'net pass yards', 'total yards', 'first downs',\n",
    "    'third downs made', 'third downs attempted',\n",
    "    'fourth downs made', 'fourth downs attempted',\n",
    "    'total plays', 'time of possession'\n",
    "]\n",
    "special_teams_keys = [\n",
    "    'punt/kickoff/fg return td', 'extra point return',\n",
    "    '2p conversions made', 'extra points made', 'field goals made'\n",
    "]\n",
    "negative_keys = ['int', 'sacked', 'fumbles', 'lost', 'turnovers', 'penalties']\n",
    "defense_keys = [\n",
    "    'sacks', 'opponent fumbles recovered', 'defensive fumble recovery td',\n",
    "    'interception return td', 'safeties', 'interceptions made',\n",
    "    'blocked punt/fg return td', 'blocked kick/punt'  # ‚úÖ Added this line\n",
    "]\n",
    "opp_keys = [col for col in team_stats_dfs_merged_features_df.columns if col.startswith('opp_')]\n",
    "odds_keys = [\n",
    "    'opening_odds', 'opening_spread', 'opening_total',\n",
    "    'line_move1', 'line_move2', 'line_move3',\n",
    "    'closing_odds', 'closing_spread', 'closing_total',\n",
    "    'opening_ml', 'closing_ml'\n",
    "]\n",
    "\n",
    "# Map to actual columns\n",
    "def resolve(keys): return [col_map[k.lower()] for k in keys if k.lower() in col_map]\n",
    "\n",
    "ordered_cols = (\n",
    "    resolve(base_keys) +\n",
    "    resolve(fantasy_keys) +\n",
    "    resolve(offense_keys) +\n",
    "    resolve(special_teams_keys) +\n",
    "    resolve(negative_keys) +\n",
    "    resolve(defense_keys) +\n",
    "    opp_keys +\n",
    "    resolve(odds_keys)\n",
    ")\n",
    "\n",
    "# Leftover columns\n",
    "remaining = [col for col in team_stats_dfs_merged_features_df.columns if col not in ordered_cols]\n",
    "\n",
    "# Reorder and rename final dataframe\n",
    "team_stats_dfs_merged_features_mod_cols_df = team_stats_dfs_merged_features_df[ordered_cols + remaining]\n",
    "\n",
    "# Compare to identify leftover columns\n",
    "missing_from_ordered = list(set(team_stats_dfs_merged_features_df.columns) - set(ordered_cols))\n",
    "print(f\"üßæ Columns not assigned to any group ({len(missing_from_ordered)}):\")\n",
    "display(sorted(missing_from_ordered))\n",
    "\n",
    "# validation check\n",
    "print(\"‚úÖ Reordered and renamed dataframe:\")\n",
    "print(f\"üìê Shape: {team_stats_dfs_merged_features_mod_cols_df.shape}\")\n",
    "display(team_stats_dfs_merged_features_mod_cols_df.head(1))\n",
    "\n",
    "# ** csv file **\n",
    "final_filename = f\"team_stats_dfs_{start_year}_{end_year}_df.csv\"\n",
    "team_stats_dfs_merged_features_mod_cols_df.to_csv(final_filename, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e5a779-3ce5-4458-93b0-c4b81cf82a94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32179070-bb76-49e6-97c7-3d26c263deb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** Final Team Defense Dataframe ***\n",
    "# output: final team defense dataframe and csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8c6b4ee-07ec-4eef-a5b2-3cc4e392c705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Defensive dataframe shape (with salary/fp): (4418, 48)\n",
      "üíæ Saved as: def_stats_dfs_2017_2024_df.csv\n"
     ]
    }
   ],
   "source": [
    "# Base identifiers and salary/points\n",
    "base_keys = [\n",
    "    'season', 'week', 'date', 'game_id', 'team_abbr', 'venue',\n",
    "    'dk_salary', 'fd_salary', 'dk_points', 'fd_points'\n",
    "]\n",
    "\n",
    "# Defensive metrics\n",
    "defense_keys = [\n",
    "    'sacks', 'opponent fumbles recovered', 'defensive fumble recovery td',\n",
    "    'interception return td', 'safeties', 'interceptions made',\n",
    "    'blocked puntfg return td', 'blocked kickpunt', 'points allowed by defense'\n",
    "]\n",
    "\n",
    "# Opponent stats\n",
    "opp_keys = [col for col in team_stats_dfs_merged_features_mod_cols_df.columns if col.startswith('opp_')]\n",
    "\n",
    "# Betting/odds data\n",
    "odds_keys = [\n",
    "    'opening odds', 'opening spread', 'opening total',\n",
    "    'line movements 1', 'line movements 2', 'line movements 3',\n",
    "    'closing odds', 'closing spread', 'closing total'\n",
    "]\n",
    "\n",
    "# Subset and extract\n",
    "def_cols = base_keys + defense_keys + opp_keys + odds_keys\n",
    "def_stats_dfs_df = team_stats_dfs_merged_features_mod_cols_df[def_cols].copy()\n",
    "\n",
    "# Export\n",
    "start_year = years[0]\n",
    "end_year = years[-1]\n",
    "final_filename = f\"def_stats_dfs_{start_year}_{end_year}_df.csv\"\n",
    "def_stats_dfs_df.to_csv(final_filename, index=False)\n",
    "\n",
    "print(f\"‚úÖ Defensive dataframe shape (with salary/fp): {def_stats_dfs_df.shape}\")\n",
    "print(f\"üíæ Saved as: {final_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276351e5-d5c0-4fcd-80ea-0c2b554e9959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db311f7-df33-4351-b30b-8e4e896438ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852ffab3-1985-42f2-b1ee-91916949ffb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe261fc-e4d0-4988-be70-6a1402c5e0c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2fa5c9-4d7f-4390-9cc7-c5a44cd1f0c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a6f05a-a16e-4ec0-8d59-22c77db529f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bedd56e-25fd-4c74-8c65-04b1876af28d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270685bb-15c8-4729-b59d-3ccaf0fa8fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307b59c7-e37a-4e89-b915-e615696bcc25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98f83f0-74db-4990-bed7-11adac854529",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
